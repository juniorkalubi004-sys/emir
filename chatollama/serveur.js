const express = require('express');
const fs = require('fs');
const path = require('path');
require('dotenv').config();

const app = express();

// Charger la configuration depuis config.json
const configPath = path.join(__dirname, 'config.json');
let config = {};
try {
  const configFile = fs.readFileSync(configPath, 'utf-8');
  config = JSON.parse(configFile);
  console.log('âœ… Configuration chargÃ©e depuis config.json');
} catch (err) {
  console.warn('âš ï¸  config.json non trouvÃ© ou invalide, utilisation des valeurs par dÃ©faut');
  config = {
    port: 3000,
    ollama: {
      apiKey: 'YOUR_API_KEY',
      apiUrl: 'https://ollama.com/api/generate',
      defaultModel: 'gpt-oss:120b-cloud'
    }
  };
}

// Variables d'environnement peuvent surcharger la configuration
const PORT = process.env.PORT || config.port || 3000;
const OLLAMA_API_KEY = process.env.OLLAMA_API_KEY || config.ollama.apiKey;
const OLLAMA_API_URL = process.env.OLLAMA_API_URL || config.ollama.apiUrl;
const DEFAULT_MODEL = process.env.OLLAMA_DEFAULT_MODEL || config.ollama.defaultModel;

// Log de confirmation
console.log('ğŸ”§ Configuration appliquÃ©e:');
console.log('   Port:', PORT);
console.log('   API URL:', OLLAMA_API_URL);
console.log('   ModÃ¨le par dÃ©faut:', DEFAULT_MODEL);
console.log('   ClÃ© API prÃ©sente:', !!OLLAMA_API_KEY);

app.use(express.json());
app.use(express.static(__dirname)); // Pour index.html

app.post('/ask', async (req, res) => {
  // On accepte dÃ©sormais un payload flexible : { prompt, model, inputs, images, ... }
  const { prompt, model, inputs, images } = req.body || {};
  console.log('ğŸ“Œ Prompt reÃ§u:', prompt);

  // Headers pour envoyer les donnÃ©es au fur et Ã  mesure
  res.setHeader('Content-Type', 'text/plain; charset=utf-8');
  res.setHeader('Transfer-Encoding', 'chunked');

  try {
    console.log('ğŸ”„ Appel API Ollama... model=', model || DEFAULT_MODEL);

    // Construire le payload en acceptant des champs multimodaux si fournis
    const payload = Object.assign(
      { stream: true },
      // permettre d'Ã©craser le modÃ¨le depuis la requÃªte cÃ´tÃ© client
      model ? { model } : { model: DEFAULT_MODEL },
      // prompt si prÃ©sent
      prompt ? { prompt } : {},
      // inputs (pour multimodal) si fournis
      inputs ? { inputs } : {},
      // images (tableau de URLs ou base64) si fournis
      images ? { images } : {}
    );

    const response = await fetch(OLLAMA_API_URL, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OLLAMA_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(payload)
    });

    console.log('ğŸ“Š Status rÃ©ponse:', response.status, response.statusText);

    if (!response.ok) {
      const errorText = await response.text();
      console.error('âŒ Erreur API:', errorText);
      res.write(`Erreur API: ${response.status} - ${errorText}`);
      res.end();
      return;
    }

    if (!response.body) {
      console.error('âŒ Pas de body dans la rÃ©ponse');
      res.write('Erreur: Pas de body dans la rÃ©ponse');
      res.end();
      return;
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let totalChunks = 0;
    let totalLines = 0;
    let totalResponse = '';

    while (true) {
      const { value, done } = await reader.read();
      if (done) {
        console.log(`âœ… Stream terminÃ©. Total chunks: ${totalChunks}, lignes: ${totalLines}, caractÃ¨res: ${totalResponse.length}`);
        break;
      }

      totalChunks++;
      const chunk = decoder.decode(value, { stream: true });
      console.log(`ğŸ“¦ Chunk ${totalChunks} (${chunk.length} bytes):`, chunk.substring(0, 100));

      // Chaque ligne = un JSON sÃ©parÃ©
      const lines = chunk.split("\n").filter(line => line.trim() !== "");
      totalLines += lines.length;

      for (const line of lines) {
        try {
          const json = JSON.parse(line);
          console.log('âœ“ JSON parsÃ©:', { done: json.done, response_len: json.response?.length || 0 });

          // Tentative d'Ã©criture aux clients : texte et, si prÃ©sent, mÃ©tadonnÃ©es multimodales
          if (json.response) {
            res.write(json.response);
            totalResponse += json.response;
            console.log('ğŸ’¬ Ã‰crit au client:', json.response.substring(0, 50));
          }

          // Si la rÃ©ponse contient des Ã©lÃ©ments image ou multimodaux, on les loggue
          if (json.images) {
            console.log('ğŸ–¼ï¸ Images dans le flux:', json.images);
            // Vous pouvez dÃ©cider ici d'Ã©mettre un wrapper JSON pour le client,
            // ex: res.write(JSON.stringify({ images: json.images }));
          }

          // Si fin â†’ terminer
          if (json.done) {
            console.log('ğŸ Fin du stream dÃ©tectÃ©e');
            res.end();
            return;
          }

        } catch (err) {
          console.error("âŒ Erreur parsing JSON:", err.message, "Ligne:", line.substring(0, 100));
        }
      }
    }

    console.log('âœ… Fin normal du stream, envoi res.end()');
    res.end();

  } catch (error) {
    console.error("âŒ Erreur Ollama Cloud:", error);
    res.status(500).send("Erreur de communication avec Ollama Cloud: " + error.message);
  }
});

app.listen(PORT, () => {
  console.log(`\nğŸš€ Serveur streaming dÃ©marrÃ© â†’ http://localhost:${PORT}\n`);
});
